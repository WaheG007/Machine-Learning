{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN ML",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s start the programming by importing essential libraries"
      ],
      "metadata": {
        "id": "7UECrGJMxw3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "WwkvOPq6x0LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing of the dataset and slicing it into independent and dependent variables\n"
      ],
      "metadata": {
        "id": "xzH280AOx-TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/sample_data/Social_Network_Ads.csv')\n",
        "X = dataset.iloc[:, [1, 2, 3]].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "QOb5M-2syk75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our dataset containing character variables we have to encode it using LabelEncoder"
      ],
      "metadata": {
        "id": "4oIdAoZq0PCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:,0] = le.fit_transform(X[:,0])"
      ],
      "metadata": {
        "id": "Zw9XBvUk0RRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are performing a train test split on the dataset. We are providing the test size as 0.20, that means our training sample contains 320 training set and test sample contains 80 test set"
      ],
      "metadata": {
        "id": "SP3gQlp10Yl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "oX9YnfBi0c2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Next, we are doing feature scaling to the training and test set of independent variables for reducing the size to smaller values"
      ],
      "metadata": {
        "id": "0rEex2wz0nFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "sg8P6JNb03Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to create and train the K Nearest Neighbor model with the training set"
      ],
      "metadata": {
        "id": "VWUwXwnH08XK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Sy2OYD09RB",
        "outputId": "502a6fcd-7edf-482b-c3d6-4500e5442b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Model is created, now we have to predict the output for the test set"
      ],
      "metadata": {
        "id": "GqoqMswE1IFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "_9fVW29w1Jpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing true and predicted value :\n",
        "\n",
        "y_test"
      ],
      "metadata": {
        "id": "xF9po4Lv1Q7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPexgthP1RzR",
        "outputId": "129f9988-68f4-4e85-f970-d6aa19359faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTjnAdT91aX1",
        "outputId": "bc55ce18-ab55-434c-eb4b-f8cab68014af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluate our model using the confusion matrix and accuracy score by comparing the predicted and actual test values"
      ],
      "metadata": {
        "id": "cXBw-s7h1dbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ac = accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "YghwzMK81eKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[[64  4]\n",
        " [ 3 29]]"
      ],
      "metadata": {
        "id": "URffIn9C2og-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy is 0.95"
      ],
      "metadata": {
        "id": "oTi-IvND26td"
      }
    }
  ]
}